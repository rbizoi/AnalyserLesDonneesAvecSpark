{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - hive</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://jupiter.olimp.fr:4041\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.0.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>spark://jupiter.olimp.fr:7077</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>PySparkShell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7fa5076835e0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialise données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- numer_sta: integer (nullable = true)\n",
      " |-- date: long (nullable = true)\n",
      " |-- pmer: integer (nullable = true)\n",
      " |-- tend: integer (nullable = true)\n",
      " |-- cod_tend: integer (nullable = true)\n",
      " |-- dd: integer (nullable = true)\n",
      " |-- ff: double (nullable = true)\n",
      " |-- t: double (nullable = true)\n",
      " |-- td: double (nullable = true)\n",
      " |-- u: integer (nullable = true)\n",
      " |-- vv: integer (nullable = true)\n",
      " |-- ww: integer (nullable = true)\n",
      " |-- w1: integer (nullable = true)\n",
      " |-- w2: integer (nullable = true)\n",
      " |-- n: integer (nullable = true)\n",
      " |-- nbas: integer (nullable = true)\n",
      " |-- hbas: integer (nullable = true)\n",
      " |-- cl: integer (nullable = true)\n",
      " |-- cm: integer (nullable = true)\n",
      " |-- ch: integer (nullable = true)\n",
      " |-- pres: integer (nullable = true)\n",
      " |-- niv_bar: integer (nullable = true)\n",
      " |-- geop: integer (nullable = true)\n",
      " |-- tend24: integer (nullable = true)\n",
      " |-- tn12: double (nullable = true)\n",
      " |-- tn24: double (nullable = true)\n",
      " |-- tx12: double (nullable = true)\n",
      " |-- tx24: double (nullable = true)\n",
      " |-- tminsol: double (nullable = true)\n",
      " |-- sw: integer (nullable = true)\n",
      " |-- tw: double (nullable = true)\n",
      " |-- raf10: double (nullable = true)\n",
      " |-- rafper: double (nullable = true)\n",
      " |-- per: integer (nullable = true)\n",
      " |-- etat_sol: integer (nullable = true)\n",
      " |-- ht_neige: double (nullable = true)\n",
      " |-- ssfrai: double (nullable = true)\n",
      " |-- perssfrai: integer (nullable = true)\n",
      " |-- rr1: double (nullable = true)\n",
      " |-- rr3: double (nullable = true)\n",
      " |-- rr6: double (nullable = true)\n",
      " |-- rr12: double (nullable = true)\n",
      " |-- rr24: double (nullable = true)\n",
      " |-- phenspe1: double (nullable = true)\n",
      " |-- phenspe2: double (nullable = true)\n",
      " |-- phenspe3: double (nullable = true)\n",
      " |-- phenspe4: double (nullable = true)\n",
      " |-- nnuage1: integer (nullable = true)\n",
      " |-- ctype1: integer (nullable = true)\n",
      " |-- hnuage1: integer (nullable = true)\n",
      " |-- nnuage2: integer (nullable = true)\n",
      " |-- ctype2: integer (nullable = true)\n",
      " |-- hnuage2: integer (nullable = true)\n",
      " |-- nnuage3: integer (nullable = true)\n",
      " |-- ctype3: integer (nullable = true)\n",
      " |-- hnuage3: integer (nullable = true)\n",
      " |-- nnuage4: integer (nullable = true)\n",
      " |-- ctype4: integer (nullable = true)\n",
      " |-- hnuage4: integer (nullable = true)\n",
      " |-- _c59: string (nullable = true)\n",
      "\n",
      "+-----+----+----+-----------+--------+----------+--------+\n",
      "|annee|mois|jour|temperature|humidite|visibilite|pression|\n",
      "+-----+----+----+-----------+--------+----------+--------+\n",
      "| 2019|  12|   1|        3.7|    0.79|      20.0|  100.86|\n",
      "| 2019|  12|   1|        2.8|    0.87|     12.23|  101.38|\n",
      "| 2019|  12|   1|        8.7|    0.75|      10.0|  101.39|\n",
      "+-----+----+----+-----------+--------+----------+--------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types     import StructType, \\\n",
    "     StructField, FloatType, \\\n",
    "     IntegerType, StringType\n",
    "\n",
    "spark = SparkSession.builder\\\n",
    "          .config(\"spark.jars.packages\",\n",
    "                         \"io.delta:delta-core_2.12:0.8.0\") \\\n",
    "          .config(\"spark.sql.extensions\",\n",
    "                         \"io.delta.sql.DeltaSparkSessionExtension\")\\\n",
    "          .getOrCreate()\n",
    "\n",
    "meteoDataFrame  = spark.read.format('csv')\\\n",
    "    .option('sep',';')\\\n",
    "    .option('header','true')\\\n",
    "    .option('nullValue','mq')\\\n",
    "    .option('inferSchema', 'true')\\\n",
    "    .load('donnees/meteo')\\\n",
    "    .cache()\n",
    "\n",
    "meteoDataFrame.columns\n",
    "meteoDataFrame.printSchema()\n",
    "\n",
    "schema = StructType([\n",
    "        StructField('Id'           , StringType() , True),\n",
    "        StructField('ville'        , StringType() , True),\n",
    "        StructField('latitude'     , FloatType() , True),\n",
    "        StructField('longitude'    , FloatType() , True),\n",
    "        StructField('altitude'     , IntegerType() , True)])\n",
    "\n",
    "villes  = spark.read.format('csv')   \\\n",
    "      .option('sep',';')                \\\n",
    "      .option('mergeSchema', 'true')    \\\n",
    "      .option('header','true')          \\\n",
    "      .schema(schema)                   \\\n",
    "      .load('/user/spark/donnees/postesSynop.csv')  \\\n",
    "      .cache()\n",
    "\n",
    "@udf(\"string\")\n",
    "def formatVille(ville):\n",
    "    if ville in ['CLERMONT-FD','MONT-DE-MARSAN',\n",
    "                                   'ST-PIERRE','ST-BARTHELEMY METEO'] :\n",
    "        return ville.title()\n",
    "    else :\n",
    "        if ville.find('-') != -1 :\n",
    "            return ville[0:ville.find('-')].title()\n",
    "        else:\n",
    "            return ville.title()\n",
    "\n",
    "villesT  = villes.select(\n",
    "                col('Id').alias('id'),\n",
    "                formatVille('ville').alias('ville'),\n",
    "               'latitude',\n",
    "               'longitude',\n",
    "               'altitude')\n",
    "\n",
    "\n",
    "meteo = meteoDataFrame.select(\n",
    "                 col('numer_sta'),\n",
    "                 to_timestamp(col('date').cast('string'),'yyyyMMddHHmmss'),\n",
    "                 col('date')[0:4].cast('int') ,\n",
    "                 col('date')[5:2].cast('int'),\n",
    "                 col('date')[7:2].cast('int'),\n",
    "                 col('date')[5:4],\n",
    "                 round(col('t') - 273.15,2),\n",
    "                 col('u') / 100 ,\n",
    "                 col('vv') / 1000 ,\n",
    "                 col('pres') / 1000,\n",
    "                 coalesce( col('rr3'),\n",
    "                           col('rr24')/8,\n",
    "                           col('rr12')/4,\n",
    "                           col('rr6')/2,\n",
    "                           col('rr1')*3  ) )\\\n",
    "             .toDF('id','date','annee','mois','jour','mois_jour','temperature',\n",
    "                   'humidite','visibilite','pression','precipitations')\\\n",
    "             .cache()\n",
    "\n",
    "meteo.select('annee','mois','jour','temperature','humidite',\n",
    "             'visibilite','pression').show(3)\n",
    "\n",
    "meteoFance = meteo.where('id < 8000')\\\n",
    "             .join(villesT,'id')\\\n",
    "             .select(initcap(regexp_replace('ville','-',' ')).alias('ville'),\n",
    "                     'annee','mois','jour','temperature',\n",
    "                     'humidite','visibilite','pression','precipitations')\n",
    "\n",
    "meteoFance.write\\\n",
    "       .mode('overwrite')\\\n",
    "       .format('parquet')\\\n",
    "       .partitionBy('annee')\\\n",
    "       .option('path', '/user/spark/donnees/meteoFrance')\\\n",
    "       .save()\n",
    "\n",
    "meteo.join(villesT,'id')\\\n",
    "     .select(initcap(regexp_replace('ville','-',' ')).alias('ville'),\n",
    "                     'annee','mois','jour','temperature',\n",
    "                     'humidite','visibilite','pression','precipitations')\\\n",
    "     .write\\\n",
    "     .mode('overwrite')\\\n",
    "     .format('parquet')\\\n",
    "     .partitionBy('annee')\\\n",
    "     .option('path', '/user/spark/donnees/meteoGlobal')\\\n",
    "     .save()\n",
    "\n",
    "data = [('Ajaccio'     ,'dfa' ),\n",
    "                  ('Angers'      ,'dfa' ),\n",
    "                  ('Angoulème'   ,'dfa' ),\n",
    "                  ('Besançon'    ,'dfa' ),\n",
    "                  ('Biarritz'    ,'dfa' ),\n",
    "                  ('Bordeaux'    ,'dfa' ),\n",
    "                  ('Brest'       ,'dfa' ),\n",
    "                  ('Caen'        ,'dfa' ),\n",
    "                  ('Clermont-Fd' ,'dfa' ),\n",
    "                  ('Dijon'       ,'dfa' ),\n",
    "                  ('Embrun'      ,'dfa' ),\n",
    "                  ('Grenoble'    ,'dfa' ),\n",
    "                  ('Lille'       ,'dfa' ),\n",
    "                  ('Limoges'     ,'dfa' ),\n",
    "                  ('Lyon'        ,'dfa' ),\n",
    "                  ('Marseille'   ,'dfa' ),\n",
    "                  ('Montpellier' ,'dfa' ),\n",
    "                  ('Nancy'       ,'dfa' ),\n",
    "                  ('Nantes'      ,'dfa' ),\n",
    "                  ('Nice'        ,'dfa' ),\n",
    "                  ('Nîmes'       ,'dfa' ),\n",
    "                  ('Orléans'     ,'dfa' ),\n",
    "                  ('Paris'       ,'dfa' )]\n",
    "\n",
    "dfa = spark.sparkContext.parallelize(data).toDF(['ville','valeur'])\n",
    "\n",
    "data = [ ('Nancy'       ,'dfb' ),\n",
    "          ('Nantes'      ,'dfb' ),\n",
    "          ('Nice'        ,'dfb' ),\n",
    "          ('Nîmes'       ,'dfb' ),\n",
    "          ('Orléans'     ,'dfb' ),\n",
    "          ('Paris'       ,'dfb' ),\n",
    "          ('Perpignan'   ,'dfb' ),\n",
    "          ('Poitiers'    ,'dfb' ),\n",
    "          ('Reims'       ,'dfb' ),\n",
    "          ('Rennes'      ,'dfb' ),\n",
    "          ('Rouen'       ,'dfb' ),\n",
    "          ('St-Quentin'  ,'dfb' ),\n",
    "          ('Strasbourg'  ,'dfb' ),\n",
    "          ('Toulon'      ,'dfb' ),\n",
    "          ('Toulouse'    ,'dfb' ),\n",
    "          ('Tours'       ,'dfb' ),\n",
    "          ('Vichy'       ,'dfb' )]\n",
    "\n",
    "dfb = spark.sparkContext.parallelize(data).toDF(['ville','valeur'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-----+----+----+---+----+-----+------+----+\n",
      "|              ville|annee|mois|jour|  t|   h|    v|     p|   e|\n",
      "+-------------------+-----+----+----+---+----+-----+------+----+\n",
      "|          Abbeville| 2019|  12|   1|3.7|0.79| 20.0|100.86| 0.0|\n",
      "|      Lille Lesquin| 2019|  12|   1|2.8|0.87|12.23|101.38| 0.0|\n",
      "|    Pte De La Hague| 2019|  12|   1|8.7|0.75| 10.0|101.39| 0.0|\n",
      "|     Caen Carpiquet| 2019|  12|   1|4.9| 0.8|30.18|100.62| 0.0|\n",
      "|         Rouen Boos| 2019|  12|   1|3.5|0.84|39.54| 99.68| 0.0|\n",
      "|       Reims Prunay| 2019|  12|   1|1.7|0.89| 20.0|100.53| 0.0|\n",
      "|     Brest Guipavas| 2019|  12|   1|7.1|0.91| 30.3|100.09| 0.0|\n",
      "|        Ploumanac'h| 2019|  12|   1|8.0|0.95| null|100.61| 2.0|\n",
      "|  Rennes St Jacques| 2019|  12|   1|6.2|0.92|18.06| 100.7| 2.0|\n",
      "|            Alencon| 2019|  12|   1|4.3|0.89|13.52| 99.52|-0.1|\n",
      "|               Orly| 2019|  12|   1|4.7|0.77|17.23| 100.4| 0.0|\n",
      "|    Troyes Barberey| 2019|  12|   1|3.9|0.83| 20.0| 100.1| 0.0|\n",
      "|        Nancy Ochey| 2019|  12|   1|1.4|0.81|26.22| 97.56| 0.0|\n",
      "|Strasbourg Entzheim| 2019|  12|   1|0.7|0.92|13.72| 100.1| 0.0|\n",
      "| Belle Ile Le Talut| 2019|  12|   1|7.8|0.93| null|100.56| 0.0|\n",
      "|  Nantes Bouguenais| 2019|  12|   1|7.8|0.99| 0.28| 100.7| 0.0|\n",
      "|              Tours| 2019|  12|   1|6.9|0.99| 3.42| 99.82| 0.6|\n",
      "|            Bourges| 2019|  12|   1|6.4|0.98| 2.11| 99.27| 3.6|\n",
      "|      Dijon Longvic| 2019|  12|   1|4.5|0.93|10.73| 98.83| 1.2|\n",
      "|      Bale Mulhouse| 2019|  12|   1|0.9|0.97| 5.22| 98.53| 0.0|\n",
      "+-------------------+-----+----+----+---+----+-----+------+----+\n",
      "only showing top 20 rows\n",
      "\n",
      "+----+----+-----------+--------+----------+--------+--------------+\n",
      "|mois|jour|temperature|humidite|visibilite|pression|precipitations|\n",
      "+----+----+-----------+--------+----------+--------+--------------+\n",
      "|  12|   1|        6.8|    0.99|      5.89|  100.61|           0.0|\n",
      "|  12|   1|        3.0|    0.99|      0.27|  100.51|           0.0|\n",
      "|  12|   1|        2.7|     1.0|      0.55|  100.46|           0.0|\n",
      "|  12|   1|        3.2|     1.0|     11.08|  100.61|          -0.1|\n",
      "|  12|   1|        8.4|    0.99|      28.4|  100.63|           0.0|\n",
      "|  12|   1|       12.8|    0.74|      57.2|  100.63|           0.0|\n",
      "|  12|   1|        5.8|    0.95|      6.08|  100.77|           0.0|\n",
      "|  12|   1|        6.1|    0.99|      7.24|  100.98|           0.0|\n",
      "|  12|   2|        6.9|    0.98|     15.64|  101.11|           0.0|\n",
      "|  12|   2|        7.0|     1.0|      3.72|  101.24|           0.0|\n",
      "|  12|   2|        8.2|    0.98|     26.33|  101.35|          -0.1|\n",
      "|  12|   2|        6.7|    0.94|     14.48|  101.57|           0.0|\n",
      "|  12|   2|        6.0|    0.89|     23.44|  101.64|           0.0|\n",
      "|  12|   2|        6.4|    0.85|     34.45|  101.63|           0.0|\n",
      "|  12|   2|        5.8|    0.88|      60.0|  101.75|           0.0|\n",
      "|  12|   2|        5.6|    0.86|     59.73|  101.76|           0.0|\n",
      "|  12|   3|        3.9|    0.86|     46.17|   101.8|           0.0|\n",
      "|  12|   3|       -0.2|    0.96|     15.32|  101.72|           0.0|\n",
      "|  12|   3|       -2.3|    0.96|      5.84|  101.63|           0.0|\n",
      "|  12|   3|        0.2|    0.96|     17.95|  101.61|           0.0|\n",
      "+----+----+-----------+--------+----------+--------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql import Window\n",
    "\n",
    "meteoFance = meteo.where('id < 8000')\\\n",
    "             .join(villes.withColumnRenamed('Id', 'id'),'id')\\\n",
    "             .select(initcap(regexp_replace('ville','-',' ')).alias('ville'),\n",
    "                     'annee','mois','jour','temperature',\n",
    "                     'humidite','visibilite','pression','precipitations')\n",
    "\n",
    "meteoFance.count()\n",
    "meteoFance.selectExpr('ville','annee','mois','jour','temperature as t',\n",
    "                      'humidite as h','visibilite as v',\n",
    "                      'pression as p','precipitations as e').show()\n",
    "\n",
    "meteoMM = meteoFance.where(\"ville = 'Mont De Marsan' and \\\n",
    "                                annee = 2019\")\\\n",
    "                     .select('mois','jour','temperature','humidite','visibilite',\n",
    "                             'pression','precipitations')\n",
    "meteoMM.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# row_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+----+----+---+-----+---+\n",
      "|mois|jour|prec|  s1|rn1|   s2|rn2|\n",
      "+----+----+----+----+---+-----+---+\n",
      "|   1|   1|-0.3|-0.3|  1| -0.3|  1|\n",
      "|   1|   2|-0.1|-0.4|  2| -0.4|  2|\n",
      "|   1|   3| 0.0|-0.4|  3| -0.4|  3|\n",
      "|   1|   4| 0.0|-0.4|  4| -0.4|  4|\n",
      "|   1|   5| 0.0|-0.4|  5| -0.4|  5|\n",
      "|   1|   6| 0.0|-0.4|  6| -0.4|  6|\n",
      "|   1|   7| 0.0|-0.4|  7| -0.4|  7|\n",
      "|   1|   8| 0.3|-0.1|  8| -0.1|  8|\n",
      "|   1|   9| 0.1| 0.0|  9|  0.0|  9|\n",
      "|   1|  10| 0.0| 0.0| 10|  0.0| 10|\n",
      "|   1|  11| 0.0| 0.0| 11|  0.0| 11|\n",
      "|   1|  12|-0.3|-0.3| 12| -0.3| 12|\n",
      "|   1|  13| 2.2| 1.9| 13|  1.9| 13|\n",
      "|   1|  14| 0.8| 2.7| 14|  2.7| 14|\n",
      "|   1|  15| 0.0| 2.7| 15|  2.7| 15|\n",
      "|   1|  16| 0.0| 2.7| 16|  2.7| 16|\n",
      "|   1|  17| 2.8| 5.5| 17|  5.5| 17|\n",
      "|   1|  18|-0.3| 5.2| 18|  5.2| 18|\n",
      "|   1|  19|-0.3| 4.9| 19|  4.9| 19|\n",
      "|   1|  20| 0.6| 5.5| 20|  5.5| 20|\n",
      "|   1|  21|-0.1| 5.4| 21|  5.4| 21|\n",
      "|   1|  22| 7.1|12.5| 22| 12.5| 22|\n",
      "|   1|  23| 9.4|21.9| 23| 21.9| 23|\n",
      "|   1|  24| 0.0|21.9| 24| 21.9| 24|\n",
      "|   1|  25|-0.2|21.7| 25| 21.7| 25|\n",
      "|   1|  26|-0.2|21.5| 26| 21.5| 26|\n",
      "|   1|  27| 5.6|27.1| 27| 27.1| 27|\n",
      "|   1|  28|13.7|40.8| 28| 40.8| 28|\n",
      "|   1|  29| 4.2|45.0| 29| 45.0| 29|\n",
      "|   1|  30| 8.8|53.8| 30| 53.8| 30|\n",
      "|   1|  31|44.2|98.0| 31| 98.0| 31|\n",
      "|   2|   1|15.2|15.2|  1|113.2| 32|\n",
      "|   2|   2| 6.9|22.1|  2|120.1| 33|\n",
      "|   2|   3| 0.0|22.1|  3|120.1| 34|\n",
      "|   2|   4| 4.9|27.0|  4|125.0| 35|\n",
      "+----+----+----+----+---+-----+---+\n",
      "only showing top 35 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "jourPOby = Window.partitionBy('mois').orderBy('jour')\n",
    "jourOby  = Window.orderBy('mois','jour')\n",
    "meteoMM.where(\"annee = 2019\")\\\n",
    "       .groupBy('mois','jour')\\\n",
    "       .agg( round(sum('precipitations'),2).alias('prec'))\\\n",
    "       .select('mois','jour',\n",
    "          col('prec').alias('prec'),\n",
    "          round(sum('prec').over(jourPOby),2).alias('s1'),\n",
    "          row_number().over(jourPOby).alias('rn1'),\n",
    "          round(sum('prec').over(jourOby),2).alias('s2'),\n",
    "          row_number().over(jourOby).alias('rn2'))\\\n",
    "       .show(35)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+----+-----+---+---+---+\n",
      "|mois|jour|prec|   s1|rn1|rk1|rk2|\n",
      "+----+----+----+-----+---+---+---+\n",
      "|  11|   5|52.5|133.2|  5|  1|  1|\n",
      "|   1|  31|44.2| 98.0| 31|  1|  2|\n",
      "|   6|   5|42.4| 60.9|  5|  1|  3|\n",
      "|   7|   9|41.4| 41.9|  9|  1|  4|\n",
      "|  11|  16|39.3|298.0| 16|  2|  5|\n",
      "|   4|   6|34.7| 57.7|  6|  1|  6|\n",
      "|  11|   4|31.5| 80.7|  4|  3|  7|\n",
      "|   4|  26|28.9|152.8| 26|  2|  8|\n",
      "|   6|  21|28.9|105.5| 21|  2|  8|\n",
      "|   5|  17|26.2| 45.8| 17|  1| 10|\n",
      "|  11|   8|26.1|202.5|  8|  4| 11|\n",
      "|  12|  12|25.0| 43.0| 12|  1| 12|\n",
      "|  12|  13|25.0| 68.0| 13|  1| 12|\n",
      "|  11|   7|22.1|176.4|  7|  5| 14|\n",
      "|   5|  18|21.8| 67.6| 18|  2| 15|\n",
      "|  11|   6|21.1|154.3|  6|  6| 16|\n",
      "|   4|  15|20.4| 89.5| 15|  3| 17|\n",
      "|   8|  11|19.7| 48.3| 11|  1| 18|\n",
      "|  11|  17|19.3|317.3| 17|  7| 19|\n",
      "|  11|  23|18.8|339.6| 23|  8| 20|\n",
      "|   6|   4|18.4| 18.5|  4|  3| 21|\n",
      "|  11|  14|18.2|242.1| 14|  9| 22|\n",
      "|  11|   2|18.1| 32.7|  2| 10| 23|\n",
      "|  11|  15|16.6|258.7| 15| 11| 24|\n",
      "|  11|   3|16.5| 49.2|  3| 12| 25|\n",
      "|   2|   1|15.2| 15.2|  1|  1| 26|\n",
      "|  10|  14|14.7| 21.7| 14|  1| 27|\n",
      "|   8|   7|14.6| 27.3|  7|  2| 28|\n",
      "|  11|   1|14.6| 14.6|  1| 13| 28|\n",
      "|  10|  15|14.1| 35.8| 15|  2| 30|\n",
      "|  12|  22|13.8| 98.5| 22|  3| 31|\n",
      "|   1|  28|13.7| 40.8| 28|  2| 32|\n",
      "|   4|  25|13.5|123.9| 25|  4| 33|\n",
      "|  10|  23|12.6| 87.5| 23|  3| 34|\n",
      "|   5|  24|12.6| 86.3| 24|  3| 34|\n",
      "+----+----+----+-----+---+---+---+\n",
      "only showing top 35 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "jourPOby = Window.partitionBy('mois').orderBy('jour')\n",
    "palmaresM  = Window.partitionBy('mois').orderBy(desc('prec'))\n",
    "palmaresA  = Window.orderBy(desc('prec'))\n",
    "meteoMM.where(\"annee = 2019\")\\\n",
    "       .groupBy('mois','jour')\\\n",
    "       .agg( round(sum('precipitations'),2).alias('prec'))\\\n",
    "       .select('mois','jour',\n",
    "          col('prec').alias('prec'),\n",
    "          round(sum('prec').over(jourPOby),2).alias('s1'),\n",
    "          row_number().over(jourPOby).alias('rn1'),\n",
    "          rank().over(palmaresM).alias('rk1'),\n",
    "          rank().over(palmaresA).alias('rk2'))\\\n",
    "       .orderBy(desc('prec'))\\\n",
    "       .show(35)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# lag lead "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+------+-----+-----+-----+\n",
      "|mois| prec|    s1|ntile|  lag| lead|\n",
      "+----+-----+------+-----+-----+-----+\n",
      "|   1| 98.0|  98.0|    1| null| 30.9|\n",
      "|   2| 30.9| 128.9|    1| 98.0| 38.1|\n",
      "|   3| 38.1| 167.0|    1| 30.9|155.4|\n",
      "|   4|155.4| 322.4|    2| 38.1| 92.6|\n",
      "|   5| 92.6| 415.0|    2|155.4|105.5|\n",
      "|   6|105.5| 520.5|    2| 92.6| 61.3|\n",
      "|   7| 61.3| 581.8|    3|105.5| 56.9|\n",
      "|   8| 56.9| 638.7|    3| 61.3| 31.4|\n",
      "|   9| 31.4| 670.1|    3| 56.9| 94.4|\n",
      "|  10| 94.4| 764.5|    4| 31.4|365.3|\n",
      "|  11|365.3|1129.8|    4| 94.4| 98.7|\n",
      "|  12| 98.7|1228.5|    4|365.3| null|\n",
      "+----+-----+------+-----+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "palmaresA  = Window.orderBy(\"mois\")\n",
    "meteoMM.where(\"annee = 2019\")\\\n",
    "       .groupBy('mois')\\\n",
    "       .agg( round(sum('precipitations'),2).alias('prec'))\\\n",
    "       .select('mois','prec',\n",
    "          round(sum('prec').over(palmaresA),2).alias('s1'),\n",
    "          ntile(4).over(palmaresA).alias('ntile'),\n",
    "          lag('prec',1).over(palmaresA).alias('lag'),\n",
    "          lead('prec',1).over(palmaresA).alias('lead'))\\\n",
    "       .show(35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
